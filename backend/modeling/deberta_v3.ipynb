{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeBERTa-v3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from mlflow.sklearn import save_model\n",
    "\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import sentencepiece\n",
    "import os\n",
    "\n",
    "from transformers import TrainingArguments, Trainer, AutoModelForSequenceClassification, AutoModel, AutoTokenizer, AutoConfig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install requirements in terminal:\n",
    "pip install transformers torch datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/data_small.csv')\n",
    "\n",
    "Y = df[\"logical_fallacies\"]\n",
    "X = df[\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['text'].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, Y, test_size=0.30, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://stackoverflow.com/questions/76868251/how-to-load-deberta-v3-properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenization after train test split to prevent data leakage\n",
    "\n",
    "#added use_fast=False to prevent tokenization error (might happen when using fast tokenization)\n",
    "tokenizer = AutoTokenizer.from_pretrained('microsoft/deberta-v3-base', use_fast=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(texts):\n",
    "    return tokenizer(\n",
    "        texts,\n",
    "        padding=\"max_length\", #ensures that all tokenized sequences are padded to the same length, padding adds special tokens to shorter sequeces so they match the maximum length\n",
    "        truncation=True, #if sequence exceeds max, it will be trucated\n",
    "        max_length=512, #for most transformer models, 512 is a common limit for maximum length\n",
    "        return_tensors=\"pt\" #converts the output to pytorch tensors\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_encodings = tokenize(X_train.to_list())\n",
    "test_encodings = tokenize(X_test.to_list())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert string labels to integers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_train = le.fit_transform(y_train) \n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset Preparation for usage in model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "needed to create a PyTorch Dataset object that:\n",
    "- organizes tokenized text\n",
    "- pairs them with corresponding labels\n",
    "- structures everything for batch processing during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#object oriented programming (class is the object), with class you can do different things, such as calling functions\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "class TextDataset(Dataset):  # Inherits from PyTorch's Dataset class\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.input_ids = encodings['input_ids']       # Token IDs from tokenizer\n",
    "        self.attention_mask = encodings['attention_mask']  # Mask for padding\n",
    "        self.labels = torch.tensor(labels)  # Convert labels to tensors\n",
    "    def __getitem__(self, idx):\n",
    "        return {\n",
    "            'input_ids': self.input_ids[idx],       # Token IDs for one sample\n",
    "            'attention_mask': self.attention_mask[idx],  # Mask for one sample\n",
    "            'labels': self.labels[idx]              # Label for one sample\n",
    "        }\n",
    "    def __len__(self):\n",
    "        return len(self.labels)  # Total number of samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TextDataset(train_encodings, y_train)\n",
    "test_dataset = TextDataset(test_encodings, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zero Shot Inference (I have computation error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # disable upper limit for memory\n",
    "# os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\"\n",
    "\n",
    "# # Allows up to 100% of available memory\n",
    "# torch.mps.set_per_process_memory_fraction(1.0)  \n",
    "\n",
    "# torch.mps.empty_cache()  # Clears unused GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Load fresh copy of base model (not train on our data)\n",
    "# num_classes = len(df[\"logical_fallacies\"].unique())\n",
    "# base_model = AutoModelForSequenceClassification.from_pretrained(\n",
    "#     \"microsoft/deberta-v3-small\",\n",
    "#     num_labels=num_classes,\n",
    "#     problem_type=\"single_label_classification\"\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def predict(model, encodings):\n",
    "#     # Set the model to evaluation mode\n",
    "#     model.eval()\n",
    "    \n",
    "#     # Use CPU\n",
    "#     device = torch.device(\"cpu\")\n",
    "#     model.to(device)\n",
    "    \n",
    "#     # Perform inference\n",
    "#     with torch.no_grad():\n",
    "#         outputs = model(\n",
    "#             input_ids=encodings[\"input_ids\"].to(device),\n",
    "#             attention_mask=encodings[\"attention_mask\"].to(device)\n",
    "#         )\n",
    "     \n",
    "#     # Apply softmax to get probabilities\n",
    "#     probabilities = torch.softmax(outputs.logits, dim=-1).cpu().numpy()\n",
    "#     return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# # Get predictions for test data\n",
    "# base_probs = predict(base_model, test_encodings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I had to change configuration of accelerate, as it might still be configured to fp16 (mixed precision):\n",
    "- type in bash accelerate confic\n",
    "- this machine\n",
    "- no distributed training\n",
    "- do you want to run your training on CPU only, say No, as MAC has GPU\n",
    "- do you wish to optimize script with torch dynamo: say \"No\" if using an Apple M1 Pro with MPS backend\n",
    "- do you want to use mixed prexision: NO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of DebertaV2ForSequenceClassification were not initialized from the model checkpoint at microsoft/deberta-v3-small and are newly initialized: ['classifier.bias', 'classifier.weight', 'pooler.dense.bias', 'pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_classes = len(df[\"logical_fallacies\"].unique())\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"microsoft/deberta-v3-small\",\n",
    "    num_labels=num_classes,\n",
    "    problem_type=\"single_label_classification\"\n",
    ")\n",
    "\n",
    "model.gradient_checkpointing_enable()  # force model to use gradient checkpointing to save memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class imbalance (We could try)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Class-balanced trainer\n",
    "# from sklearn.utils.class_weight import compute_class_weight\n",
    "# class_weights = compute_class_weight('balanced', classes=np.unique(y_train), y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Confguration "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/maren/Library/CloudStorage/OneDrive-PersoÌˆnlich/Dokumente/neue_fische/Capstone Project/Capstone_project/backend/.venv/lib/python3.11/site-packages/transformers/training_args.py:1611: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of ðŸ¤— Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "training_args = TrainingArguments(\n",
    "    # output_dir='./results', # to sve results\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=4, #small to save memory\n",
    "    per_device_eval_batch_size=8, #small to save memory\n",
    "    learning_rate=2e-5, #standard for deberta; maybe try 6e-6\n",
    "    weight_decay=0.01,\n",
    "    evaluation_strategy=\"epoch\",\n",
    "    logging_steps=50,\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True\n",
    ")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    preds = p.predictions.argmax(-1)\n",
    "    return {'accuracy': accuracy_score(p.label_ids, preds)}\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Execute Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mps.empty_cache()  # Clears unused GPU memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# disable upper limit for memory\n",
    "os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\"\n",
    "\n",
    "# Allows up to 100% of available memory\n",
    "torch.mps.set_per_process_memory_fraction(1.0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='2625' max='2625' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [2625/2625 32:26, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.939800</td>\n",
       "      <td>0.961467</td>\n",
       "      <td>0.682667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.740400</td>\n",
       "      <td>0.926966</td>\n",
       "      <td>0.731333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.550900</td>\n",
       "      <td>1.017781</td>\n",
       "      <td>0.749333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7313\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7313\n"
     ]
    }
   ],
   "source": [
    "results = trainer.evaluate()\n",
    "print(f\"Test Accuracy: {results['eval_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = trainer.predict(test_dataset)\n",
    "predictions = np.argmax(output.predictions, axis=1)\n",
    "y_true = output.label_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.60      0.65       159\n",
      "           1       0.69      0.32      0.44        97\n",
      "           2       0.73      0.66      0.69       227\n",
      "           3       0.82      0.56      0.67       133\n",
      "           4       0.58      0.63      0.60       202\n",
      "           5       0.77      0.91      0.83       682\n",
      "\n",
      "    accuracy                           0.73      1500\n",
      "   macro avg       0.72      0.61      0.65      1500\n",
      "weighted avg       0.73      0.73      0.72      1500\n",
      "\n",
      "Confusion Matrix:\n",
      "[[ 96   6  25   2  11  19]\n",
      " [  6  31   9   0  14  37]\n",
      " [ 11   2 150   5  24  35]\n",
      " [  3   0   5  75   9  41]\n",
      " [  6   3  12   2 127  52]\n",
      " [ 14   3   5   7  35 618]]\n"
     ]
    }
   ],
   "source": [
    "# Generate classification report\n",
    "print(classification_report(y_true, predictions))\n",
    "\n",
    "# Generate confusion matrix\n",
    "cm = confusion_matrix(y_true, predictions)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/04/01 15:07:59 WARNING mlflow.sklearn: Model was missing function: predict. Not logging python_function flavor!\n"
     ]
    }
   ],
   "source": [
    "path = \"models/LLM_deberta_v3_small\"\n",
    "# model.save_pretrained(path)\n",
    "save_model(sk_model=model, path=path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
